{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from scipy import optimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 420"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent method\n",
    "Since matrix $P$ is given in the problem statement, we will set it uniformly distributed. Let $n = 4$ and $m = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03010262  0.30429777  0.14931357  0.20986587]\n",
      " [ 0.01971894  0.38457691  0.26875316  0.15398647]\n",
      " [ 0.42623351  0.09273376  0.14989082  0.24481052]\n",
      " [ 0.17456529  0.10720182  0.19368007  0.09111684]\n",
      " [ 0.34937964  0.11118974  0.23836238  0.30022029]]\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "m = 5\n",
    "P = np.array([np.random.uniform(size=n) for x in np.zeros(m)])\n",
    "P /= P.sum(axis=0)\n",
    "c_t = np.array([-np.sum(x * np.log2(x)) for x in P.T])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    #get projection of x\n",
    "    x_ = euclidean_proj_simplex(x)\n",
    "    y = P @ x_\n",
    "    if (np.min(y) <= 0):\n",
    "        return np.inf\n",
    "    return c_t @ x_ + np.sum(y * np.log(y) / np.log(2))\n",
    "\n",
    "def grad_f(x):\n",
    "    #get projection of x\n",
    "    x_ = euclidean_proj_simplex(x)\n",
    "    y = P @ x_\n",
    "    if (np.min(y) <= 0):\n",
    "        raise ValueError\n",
    "    grad = c_t.copy()\n",
    "    tmp = []\n",
    "    for i in range(m):\n",
    "        tmp.append(P[i] * (np.log(P[i] @ x_) + 1) / np.log(2))\n",
    "    tmp_sum = np.sum(np.array(tmp), axis=0)\n",
    "    return grad + tmp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_proj_simplex(v, s=1):\n",
    "    n, = v.shape  \n",
    "    if v.sum() == s and np.alltrue(v >= 0):\n",
    "        return v\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]\n",
    "    theta = (cssv[rho] - s) / (rho + 1.0)\n",
    "    w = (v - theta).clip(min=0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoppingCriteria:\n",
    "    def __init__(self, max_iterations=np.inf, min_grad_norm=0):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.min_grad_norm = min_grad_norm\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        cur_iterations = state['iterations']\n",
    "        cur_grad_norm = np.linalg.norm(state['cur_grad'], ord=2)\n",
    "        dif_x = np.linalg.norm(state['x'] - state['prev_x'], ord=2)\n",
    "        return (cur_iterations >= self.max_iterations or cur_grad_norm <= self.min_grad_norm or dif_x <= self.min_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepSearchFastestTernary:\n",
    "    def __init__(self, precision):\n",
    "        self.precision = precision\n",
    "        self.left = 0\n",
    "        self.right = None\n",
    "        \n",
    "    def __update_starting_points(self, state, init_kpower=-2):\n",
    "        k_power = init_kpower\n",
    "        f = state['f']\n",
    "        x = state['x']\n",
    "        dx = state['dx']\n",
    "        while f(x + 2**k_power * dx) > f(x + 2**(k_power + 1) * dx):\n",
    "            k_power += 1\n",
    "        if k_power == init_kpower:\n",
    "            self.left = 0\n",
    "        else:\n",
    "            self.left = 2**(k_power - 1)\n",
    "        self.right = 2**(k_power + 1)\n",
    "            \n",
    "            \n",
    "    def __call__(self, state):\n",
    "        f = state['f']\n",
    "        x = state['x']\n",
    "        dx = state['dx']\n",
    "        \n",
    "        self.__update_starting_points(state) # update self.left and self.right\n",
    "        \n",
    "        right = self.right\n",
    "        left = self.left\n",
    "        \n",
    "        while True:\n",
    "            if abs(right - left) < self.precision:\n",
    "                return (left + right)/2\n",
    "\n",
    "            left_div = left + (right - left)/3\n",
    "            right_div = right - (right - left)/3\n",
    "\n",
    "            f_left = f(x + left_div * dx)\n",
    "            f_right = f(x + right_div * dx)\n",
    "            \n",
    "            if f_left == np.inf:\n",
    "                right = right_div\n",
    "            else:\n",
    "                if f_left < f_right:\n",
    "                    right = right_div\n",
    "                else:\n",
    "                    left = left_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepSearchBacktracking:\n",
    "    def __init__(self, alpha=0.3, beta=0.7):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "            \n",
    "    def __call__(self, state):\n",
    "        t = 1\n",
    "        f = state['f']\n",
    "        grad_f = state['grad_f']\n",
    "        x = state['x']\n",
    "        dx = state['dx']\n",
    "        grad_proj = euclidean_proj_simplex(grad_f(x))\n",
    "#         print('left and right ', f(x + t * dx), f(x) + self.alpha * t * grad_proj.T @ (-grad_proj))\n",
    "        while f(x + t * dx) > f(x) + self.alpha * t * grad_proj.T @ dx:\n",
    "#             print('left and right ', f(x + t * dx), f(x) + self.alpha * t * grad_proj.T @ (-grad_proj))\n",
    "            t *= self.beta\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepSearchConstant:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "            \n",
    "    def __call__(self, state):\n",
    "        return self.lr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentMethod:\n",
    "    def __init__(self, t_search, stopping_criteria):\n",
    "        self.t_search = t_search\n",
    "        self.stopping_criteria = stopping_criteria\n",
    "    \n",
    "    def fit(self, f, grad_f, x_0):\n",
    "        x = x_0.copy()\n",
    "        state = dict()\n",
    "        state['f'] = f\n",
    "        state['grad_f'] = grad_f\n",
    "        state['x'] = x\n",
    "        # hardcoded xD\n",
    "        state['prev_x'] = np.ones(n) / n\n",
    "        \n",
    "        state['iterations'] = 0\n",
    "        state['time'] = time.time()\n",
    "        while True:\n",
    "            state['cur_grad'] = grad_f(state['x'])\n",
    "            state['dx'] = -grad_f(state['x'])\n",
    "            if self.stopping_criteria(state):\n",
    "                break\n",
    "            t = self.t_search(state)\n",
    "            state['prev_x'] = state['x'].copy()\n",
    "            state['x'] -= t * state['cur_grad']\n",
    "            #take projection on simplex\n",
    "            state['x'] = euclidean_proj_simplex(state['x'])\n",
    "            state['iterations'] += 1\n",
    "            \n",
    "        state['time'] = time.time() - state['time']\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 =  [ 0.2770532   0.06445471  0.32984464  0.32864745]\n",
      "f_min = -0.377917147549\n",
      "time =  0.06444215774536133\n",
      "iterations =  10\n",
      "x =  [ 0.53978498  0.46021502  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "stopping_criteria = StoppingCriteria(min_grad_norm=1e-12)\n",
    "t_search = StepSearchFastestTernary(precision=1e-7)\n",
    "grad = GradientDescentMethod(t_search=t_search, stopping_criteria=stopping_criteria)\n",
    "x_0 = np.random.uniform(low=0, high=1, size=n)\n",
    "x_0 /= np.sum(x_0)\n",
    "state = grad.fit(f, grad_f, x_0)\n",
    "print('x_0 = ', x_0)\n",
    "print('f_min =', f(state['x']))\n",
    "print('time = ', state['time'])\n",
    "print(\"iterations = \", state['iterations'])\n",
    "print('x = ',state['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 =  [ 0.2770532   0.06445471  0.32984464  0.32864745]\n",
      "f_min = -0.377917147549\n",
      "time =  0.028169870376586914\n",
      "iterations =  54\n",
      "x =  [ 0.53978498  0.46021502  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "stopping_criteria = StoppingCriteria(min_grad_norm=1e-12)\n",
    "t_search = StepSearchConstant(lr=1.2)\n",
    "grad = GradientDescentMethod(t_search=t_search, stopping_criteria=stopping_criteria)\n",
    "state = grad.fit(f, grad_f, x_0)\n",
    "print('x_0 = ', x_0)\n",
    "print('f_min =', f(state['x']))\n",
    "print('time = ', state['time'])\n",
    "print(\"iterations = \", state['iterations'])\n",
    "print('x = ',state['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_0 =  [ 0.2770532   0.06445471  0.32984464  0.32864745]\n",
      "f_min = -0.377917147511\n",
      "time =  0.015752077102661133\n",
      "iterations =  8\n",
      "x =  [ 0.53979029  0.46020971  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "stopping_criteria = StoppingCriteria(min_grad_norm=1e-12)\n",
    "t_search = StepSearchBacktracking(alpha=1e-8)\n",
    "grad = GradientDescentMethod(t_search=t_search, stopping_criteria=stopping_criteria)\n",
    "state = grad.fit(f, grad_f, x_0)\n",
    "print('x_0 = ', x_0)\n",
    "print('f_min =', f(state['x']))\n",
    "print('time = ', state['time'])\n",
    "print(\"iterations = \", state['iterations'])\n",
    "print('x = ',state['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1},\n",
    "        {'type': 'ineq', 'fun': lambda x: x[0]},\n",
    "        {'type': 'ineq', 'fun': lambda x: x[1]},\n",
    "       {'type': 'ineq', 'fun': lambda x: x[2]},\n",
    "       {'type': 'ineq', 'fun': lambda x: x[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: -0.37791714745771166\n",
      "     jac: array([ -1.10417604e-05,   1.10417604e-05,   1.97496980e-01,\n",
      "         2.22076014e-01])\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 30\n",
      "     nit: 5\n",
      "    njev: 5\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([  5.39776754e-01,   4.60223246e-01,  -6.72205347e-18,\n",
      "         9.75239854e-17])\n"
     ]
    }
   ],
   "source": [
    "print(optimize.minimize(f, x_0, method='SLSQP',\n",
    "               constraints=cons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
